{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e03630b",
   "metadata": {},
   "source": [
    "# Battery SOH Pipeline Notebook\n",
    "\n",
    "This notebook reproduces the full pipeline: data loading, plotting, HI extraction, correlation-based feature selection, PSO-tuned SVR/LSTM/CNN training, and model saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d14f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports & global settings\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.svm import SVR\n",
    "import pyswarms as ps\n",
    "\n",
    "# Adjust this path if needed\n",
    "DATA_DIR = \"data\"\n",
    "BATTERIES = [\"B0005\", \"B0006\", \"B0007\"]\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d6917d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fed7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load charge / discharge CSVs per battery\n",
    "def load_battery(batt):\n",
    "    path = os.path.join(DATA_DIR, batt)\n",
    "    charge = pd.read_csv(os.path.join(path, f\"{batt}_charge_data.csv\"))\n",
    "    discharge = pd.read_csv(os.path.join(path, f\"{batt}_discharge_data.csv\"))\n",
    "    return charge, discharge\n",
    "\n",
    "# Example: inspect one cycle from B0005\n",
    "charge5, dis5 = load_battery(\"B0005\")\n",
    "print(charge5.columns, dis5.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1ef9d8",
   "metadata": {},
   "source": [
    "## Exploratory Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d96de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Plot example cycles for one battery\n",
    "def plot_cycle(charge, discharge, cycle_id):\n",
    "    c = charge[charge[\"cycle_id\"] == cycle_id]\n",
    "    d = discharge[discharge[\"cycle_id\"] == cycle_id]\n",
    "    fig, axs = plt.subplots(3, 2, figsize=(12, 8))\n",
    "    axs = axs.ravel()\n",
    "    axs[0].plot(c[\"time_s\"], c[\"temp_C\"]); axs[0].set_title(\"Charge Temp vs Time\")\n",
    "    axs[1].plot(d[\"time_s\"], d[\"temp_C\"]); axs[1].set_title(\"Discharge Temp vs Time\")\n",
    "    axs[2].plot(c[\"time_s\"], c[\"voltage_V\"]); axs[2].set_title(\"Charge Voltage\")\n",
    "    axs[3].plot(d[\"time_s\"], d[\"voltage_V\"]); axs[3].set_title(\"Discharge Voltage\")\n",
    "    axs[4].plot(c[\"time_s\"], c[\"current_A\"]); axs[4].set_title(\"Charge Current\")\n",
    "    axs[5].plot(d[\"time_s\"], d[\"current_A\"]); axs[5].set_title(\"Discharge Current\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_cycle(charge5, dis5, cycle_id=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d94968",
   "metadata": {},
   "source": [
    "## Health‐Indicator Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430e4b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: HI extraction and feature matrix\n",
    "def extract_HIs(cycle_charge, cycle_discharge):\n",
    "    t_c, T_c, V_c, I_c = cycle_charge[\"time_s\"].values, cycle_charge[\"temp_C\"].values, cycle_charge[\"voltage_V\"].values, cycle_charge[\"current_A\"].values\n",
    "    t_d, T_d, V_d, I_d = cycle_discharge[\"time_s\"].values, cycle_discharge[\"temp_C\"].values, cycle_discharge[\"voltage_V\"].values, cycle_discharge[\"current_A\"].values\n",
    "\n",
    "    HI1 = t_c[np.argmax(T_c)]\n",
    "    HI2 = T_c.max()\n",
    "    HI3 = T_c.mean()\n",
    "    HI4 = t_d[np.argmax(T_d)]\n",
    "    HI5 = T_d.max()\n",
    "    HI6 = T_d.mean()\n",
    "    HI7 = V_c[0]\n",
    "    V_at_ref = np.interp(1000, t_c, V_c)\n",
    "    HI8 = 4.2 - V_at_ref\n",
    "    idx_cut = np.argmax(V_c >= 4.2)\n",
    "    HI9 = np.trapz(V_c[:idx_cut], t_c[:idx_cut])\n",
    "    HI10 = V_d[0] - np.interp(100, t_d, V_d)\n",
    "    HI11 = V_d.mean()\n",
    "    idx_cv = idx_cut\n",
    "    I_cv = I_c[idx_cv:]\n",
    "    t_cv = t_c[idx_cv:]\n",
    "    try:\n",
    "        t12 = t_cv[np.where(I_cv <= 0.2)[0][0]] - t_cv[np.where(I_cv <= 0.5)[0][0]]\n",
    "    except IndexError:\n",
    "        t12 = np.nan\n",
    "    HI12 = t12\n",
    "    HI13 = I_c[0] - np.interp(100, t_cv, I_cv)\n",
    "    HI14 = np.trapz(I_cv, t_cv)\n",
    "    HI15 = I_d.mean()\n",
    "    HI16 = np.trapz(V_c * I_c, t_c)\n",
    "\n",
    "    return [HI1, HI2, HI3, HI4, HI5, HI6, HI7, HI8, HI9, HI10, HI11, HI12, HI13, HI14, HI15, HI16]\n",
    "\n",
    "# Build the DataFrame\n",
    "all_features = []\n",
    "all_capacity = []\n",
    "for batt in BATTERIES:\n",
    "    ch, di = load_battery(batt)\n",
    "    for cid in sorted(ch[\"cycle_id\"].unique()):\n",
    "        feat = extract_HIs(ch[ch[\"cycle_id\"]==cid], di[di[\"cycle_id\"]==cid])\n",
    "        cap  = float(di[di[\"cycle_id\"]==cid][\"capacity_Ah\"].iloc[0])\n",
    "        all_features.append(feat)\n",
    "        all_capacity.append(cap)\n",
    "\n",
    "HI_cols = [f\"HI{i}\" for i in range(1,17)]\n",
    "df = pd.DataFrame(all_features, columns=HI_cols)\n",
    "df[\"capacity\"] = all_capacity\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aae16a",
   "metadata": {},
   "source": [
    "## Correlation & Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66471f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: correlation filtering (|r| >= 0.75)\n",
    "corrs = df.corr()[\"capacity\"].abs().loc[HI_cols]\n",
    "to_keep = corrs[corrs >= 0.75].index.tolist()\n",
    "print(\"Retained HIs:\", to_keep)\n",
    "\n",
    "X = df[to_keep].values\n",
    "y = df[\"capacity\"].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636ea433",
   "metadata": {},
   "source": [
    "## Train/Val/Test Split & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63bfce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: split & scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "X_train, X_val,  y_train, y_val  = train_test_split(X_train, y_train, test_size=0.25, shuffle=False)\n",
    "\n",
    "scaler_X = MinMaxScaler().fit(X_train)\n",
    "scaler_y = MinMaxScaler().fit(y_train)\n",
    "\n",
    "X_train_s = scaler_X.transform(X_train)\n",
    "X_val_s   = scaler_X.transform(X_val)\n",
    "X_test_s  = scaler_X.transform(X_test)\n",
    "y_train_s = scaler_y.transform(y_train).ravel()\n",
    "y_val_s   = scaler_y.transform(y_val).ravel()\n",
    "y_test_s  = scaler_y.transform(y_test).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db665ed5",
   "metadata": {},
   "source": [
    "## PSO for Hyperparameter Search (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c11e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: PSO objective for SVR\n",
    "def svr_obj(params):\n",
    "    C, gamma, eps = params\n",
    "    svr = SVR(kernel=\"rbf\", C=C, gamma=gamma, epsilon=eps)\n",
    "    svr.fit(X_train_s, y_train_s)\n",
    "    preds = svr.predict(X_val_s)\n",
    "    return np.sqrt(np.mean((preds - y_val_s)**2))\n",
    "\n",
    "bounds = (np.array([1,1e-4,1e-4]), np.array([1000,1e-1,1e-1]))\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=20, dimensions=3,\n",
    "                                    options={\"c1\":0.5,\"c2\":0.3,\"w\":0.9},\n",
    "                                    bounds=bounds)\n",
    "best_cost, best_params = optimizer.optimize(lambda p: np.apply_along_axis(svr_obj,1,p), iters=30)\n",
    "print(\"SVR PSO →\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03125b49",
   "metadata": {},
   "source": [
    "## Train Final SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f6c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: final SVR training & evaluate\n",
    "C_opt, gamma_opt, eps_opt = best_params\n",
    "model_svr = SVR(kernel=\"rbf\", C=C_opt, gamma=gamma_opt, epsilon=eps_opt)\n",
    "model_svr.fit(np.vstack([X_train_s, X_val_s]), np.concatenate([y_train_s, y_val_s]))\n",
    "\n",
    "y_pred = model_svr.predict(X_test_s)\n",
    "rmse = np.sqrt(np.mean((y_pred - y_test_s)**2))\n",
    "print(\"Test RMSE (scaled):\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f3d651",
   "metadata": {},
   "source": [
    "## PSO-LSTM & PSO-CNN (Outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88890bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: reshape for sequence models\n",
    "X_train_seq = X_train_s.reshape(-1, 1, X_train_s.shape[1])\n",
    "X_val_seq   = X_val_s.reshape(-1, 1, X_val_s.shape[1])\n",
    "X_test_seq  = X_test_s.reshape(-1, 1, X_test_s.shape[1])\n",
    "\n",
    "def build_lstm(units, lr):\n",
    "    m = Sequential([LSTM(int(units), input_shape=(1, X_train_s.shape[1])), Dense(1)])\n",
    "    m.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    return m\n",
    "\n",
    "def lstm_obj(params):\n",
    "    units, lr = params\n",
    "    m = build_lstm(units, lr)\n",
    "    m.fit(X_train_seq, y_train_s, validation_data=(X_val_seq, y_val_s),\n",
    "          epochs=50, batch_size=32, verbose=0,\n",
    "          callbacks=[EarlyStopping(patience=5)])\n",
    "    pred = m.predict(X_val_seq).ravel()\n",
    "    return np.sqrt(np.mean((pred - y_val_s)**2))\n",
    "\n",
    "# Similar PSO for CNN can be added here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa946f5a",
   "metadata": {},
   "source": [
    "## Save Models & Flask Snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1328ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: save models and example Flask endpoint\n",
    "import joblib\n",
    "model_dir = \"models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "joblib.dump(model_svr, os.path.join(model_dir, \"svr.pkl\"))\n",
    "# example for Keras models:\n",
    "# model_lstm.save(os.path.join(model_dir, \"lstm.h5\"))\n",
    "# model_cnn.save(os.path.join(model_dir, \"cnn.h5\"))\n",
    "\n",
    "# Flask snippet (add to your existing backend):\n",
    "# from flask import Flask, request, jsonify\n",
    "# import joblib\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.models import load_model\n",
    "#\n",
    "# app = Flask(__name__)\n",
    "# svr  = joblib.load(\"models/svr.pkl\")\n",
    "#\n",
    "# @app.route('/predict', methods=['POST'])\n",
    "# def predict():\n",
    "#     data = request.json\n",
    "#     feats = np.array([data[h] for h in to_keep]).reshape(1,-1)\n",
    "#     feats_s = scaler_X.transform(feats)\n",
    "#     yhat = svr.predict(feats_s)\n",
    "#     return jsonify({\"soh_est\": float(yhat)})"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
